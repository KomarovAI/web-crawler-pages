name: üåê Deploy to Pages

on:
  workflow_dispatch:
    inputs:
      source_repo:
        description: 'Source repository (KomarovAI/web-crawler)'
        required: true
        default: 'KomarovAI/web-crawler'
      run_id:
        description: 'Workflow run ID from web-crawler (look at Actions tab)'
        required: true
      site_domain:
        description: 'Domain folder name (e.g., callmedley-com)'
        required: true
        default: 'callmedley-com'

jobs:
  verify:
    name: 'üîç Verify Database'
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      actions: read
    
    steps:
      - name: üì• Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          merge-multiple: false
          repository: ${{ inputs.source_repo }}
          run-id: ${{ inputs.run_id }}
          github-token: ${{ secrets.GH_PAT }}

      - name: üóÇÔ∏è Extract ZIP archives
        run: |
          for i in {1..5}; do
            found=0
            find artifacts -name "*.zip" -type f | while read zip; do
              found=$((found+1))
              unzip -q "$zip" -d "$(dirname "$zip")"
              rm "$zip"
            done
            if [ $found -eq 0 ]; then break; fi
          done

      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ‚úÖ Verify databases
        run: |
          python3 << 'VERIFY_EOF'
          import sqlite3
          from pathlib import Path
          import sys
          
          for db_file in sorted(Path('artifacts').glob('db-*/*.db')):
            print(f"\nüì¶ {db_file.parent.name.replace('db-', '')}")
            conn = sqlite3.connect(str(db_file))
            cursor = conn.cursor()
            
            cursor.execute("PRAGMA table_info(pages)")
            cols = [row[1] for row in cursor.fetchall()]
            print(f"  ALL COLUMNS: {cols}")
            
            cursor.execute("SELECT COUNT(*) FROM pages")
            print(f"  ‚úÖ Pages: {cursor.fetchone()[0]}")
            conn.close()
          VERIFY_EOF

  build:
    name: 'üèóÔ∏è Build HTML'
    needs: verify
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      actions: read
    
    steps:
      - name: üì• Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          merge-multiple: false
          repository: ${{ inputs.source_repo }}
          run-id: ${{ inputs.run_id }}
          github-token: ${{ secrets.GH_PAT }}

      - name: üóÇÔ∏è Extract ZIP archives
        run: |
          for i in {1..5}; do
            find artifacts -name "*.zip" -type f -exec sh -c 'unzip -q "$1" -d "$(dirname "$1")" && rm "$1"' _ {} \;
          done

      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: üèóÔ∏è Build HTML pages
        run: |
          python3 << 'BUILD_EOF'
          import sqlite3
          import shutil
          from pathlib import Path
          
          output_dir = Path('sites')
          output_dir.mkdir(exist_ok=True)
          
          print("\n" + "="*60)
          print("üèóÔ∏è  BUILDING STATIC SITE")
          print("="*60 + "\n")
          
          for db_dir in sorted(Path('artifacts').glob('db-*')):
            domain = db_dir.name.replace('db-', '')
            db_file = db_dir / f"{domain}.db"
            
            if not db_file.exists():
              continue
            
            print(f"üì¶ Building: {domain}")
            
            site_dir = output_dir / domain
            site_dir.mkdir(exist_ok=True)
            pages_dir = site_dir / 'pages'
            pages_dir.mkdir(exist_ok=True)
            
            shutil.copy(db_file, site_dir / f"{domain}.db")
            
            conn = sqlite3.connect(str(db_file))
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # Get ALL columns
            cursor.execute("PRAGMA table_info(pages)")
            all_cols = [row[1] for row in cursor.fetchall()]
            print(f"  Columns: {all_cols}")
            
            # Find columns by pattern
            url_col = next((c for c in all_cols if c.lower() in ['url', 'href', 'uri']), all_cols[0] if all_cols else 'id')
            print(f"  Using url_col: {url_col}")
            
            query = f"SELECT * FROM pages ORDER BY id"
            cursor.execute(query)
            pages = cursor.fetchall()
            print(f"  üìÑ {len(pages)} pages")
            
            # Build index
            html = '''<!DOCTYPE html>
<html><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>{}</title><style>
* {{ margin: 0; padding: 0; box-sizing: border-box; }}
body {{ font-family: -apple-system, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 40px 20px; }}
.container {{ max-width: 1200px; margin: 0 auto; }}
h1 {{ color: white; text-align: center; margin-bottom: 40px; font-size: 2.5em; }}
.grid {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(280px, 1fr)); gap: 20px; }}
.card {{ background: white; border-radius: 8px; padding: 20px; box-shadow: 0 4px 15px rgba(0,0,0,0.2); transition: transform 0.2s; }}
.card:hover {{ transform: translateY(-5px); }}
.card h3 {{ color: #333; margin-bottom: 10px; }}
.card p {{ color: #666; font-size: 0.9em; word-break: break-all; }}
.card a {{ display: inline-block; margin-top: 15px; padding: 8px 12px; background: #667eea; color: white; text-decoration: none; border-radius: 4px; }}
.card a:hover {{ background: #764ba2; }}
</style></head><body>
<div class="container"><h1>üìñ {}</h1><div class="grid">'''.format(domain, domain)
            
            for idx, page in enumerate(pages, 1):
              page_dict = dict(page)
              url_val = str(page_dict.get(url_col, 'N/A'))[:60]
              html += f'<div class="card"><h3>Page {idx}</h3><p>{url_val}</p><a href="pages/page-{idx:05d}.html">View ‚Üí</a></div>'
            
            html += '</div></div></body></html>'
            with open(site_dir / 'index.html', 'w', encoding='utf-8') as f:
              f.write(html)
            
            # Build individual pages
            for idx, page in enumerate(pages, 1):
              page_dict = dict(page)
              url_val = str(page_dict.get(url_col, 'N/A'))
              content_val = str(page_dict.get(next((c for c in all_cols if c.lower() in ['content', 'body', 'html', 'text']), None), ''))[:5000] if next((c for c in all_cols if c.lower() in ['content', 'body', 'html', 'text']), None) else ''
              
              page_html = f'''<!DOCTYPE html>
<html><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Page {idx}</title><style>
* {{ margin: 0; padding: 0; box-sizing: border-box; }}
body {{ font-family: -apple-system, sans-serif; background: #f5f5f5; }}
.container {{ max-width: 900px; margin: 0 auto; background: white; padding: 30px; }}
.header {{ border-bottom: 2px solid #667eea; margin-bottom: 30px; }}
.header h1 {{ color: #667eea; }}
.meta {{ color: #666; font-size: 0.9em; margin: 5px 0; }}
.nav a {{ display: inline-block; padding: 8px 15px; background: #667eea; color: white; text-decoration: none; border-radius: 4px; }}
.nav a:hover {{ background: #764ba2; }}
</style></head><body>
<div class="container"><div class="nav" style="margin-bottom: 20px;"><a href="../index.html">‚Üê Back</a></div>
<div class="header"><h1>Page {idx}</h1><div class="meta"><b>URL:</b> {url_val}</div></div>
<div style="margin-top: 30px; line-height: 1.8;">{content_val}</div></div></body></html>'''
              
              with open(pages_dir / f'page-{idx:05d}.html', 'w', encoding='utf-8') as f:
                f.write(page_html)
            
            conn.close()
            print(f"  ‚úÖ Done\n")
          
          print("="*60)
          print("‚úÖ Build complete!")
          print("="*60)
          BUILD_EOF

      - name: üì§ Upload build
        uses: actions/upload-artifact@v4
        with:
          name: sites-build
          path: sites/
          retention-days: 1

  deploy:
    name: 'üöÄ Deploy'
    needs: build
    runs-on: ubuntu-24.04
    permissions:
      contents: write
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          name: sites-build
          path: sites/
      - uses: actions/configure-pages@v4
      - uses: actions/jekyll-build-pages@v1
        with:
          source: ./
          destination: ./_site
      - uses: actions/upload-pages-artifact@v3
        with:
          path: './_site'
      - uses: actions/deploy-pages@v4
