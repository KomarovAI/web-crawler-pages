name: Deploy Archive to GitHub Pages

on:
  workflow_dispatch:
    inputs:
      artifact_name:
        description: 'Ð˜Ð¼Ñ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ð° (archive-HASH)'
        required: true
        type: string
      run_id:
        description: 'ID Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð¸Ð· web-crawler Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ'
        required: true
        type: string
      domain:
        description: 'Ð”Ð¾Ð¼ÐµÐ½ ÑÐ°Ð¹Ñ‚Ð° (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ callmedley.com)'
        required: true
        type: string
        default: 'callmedley.com'

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download Archive
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.artifact_name }}
          path: artifacts
          repository: KomarovAI/web-crawler
          run-id: ${{ inputs.run_id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract Archives
        run: |
          echo "ðŸ”“ Ð Ð°ÑÐ¿Ð°ÐºÐ¾Ð²ÐºÐ° Ð°Ñ€Ñ…Ð¸Ð²Ð¾Ð²..."
          find artifacts -name "*.zip" -type f 2>/dev/null | while read zip; do
            dir=$(dirname "$zip")
            echo "ðŸ“¦ Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÑŽ: $zip"
            unzip -q -o "$zip" -d "$dir" || true
            rm "$zip"
          done
          echo "âœ… Ð Ð°ÑÐ¿Ð°ÐºÐ¾Ð²ÐºÐ° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°"
          
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Process Archive & Rewrite Links
        env:
          ARTIFACT_NAME: ${{ inputs.artifact_name }}
          DOMAIN: ${{ inputs.domain }}
        run: |
          cat > process_archive.py << 'EOFPYTHON'
import sqlite3
import os
import re
from pathlib import Path
from urllib.parse import urlparse, unquote

def process_archive():
    artifact_name = os.environ['ARTIFACT_NAME']
    domain = os.environ['DOMAIN']
    domain_clean = domain.replace('.', '')
    
    # Ð”Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿ÑƒÑ‚ÑŒ Ðº Ð°Ñ€Ñ…Ð¸Ð²Ñƒ
    archive_base = Path(f"artifacts/{artifact_name}/archive/{domain}")
    db_path = archive_base / f"{domain_clean}.db"
    
    if not db_path.exists():
        print(f"âŒ Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°: {db_path}")
        print(f"ðŸ“‚ Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ artifacts/:")
        for p in Path("artifacts").rglob("*"):
            print(f"  {p}")
        return
    
    output_dir = Path("pages")
    output_dir.mkdir(exist_ok=True)
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT url, html FROM pages ORDER BY id")
    pages = cursor.fetchall()
    print(f"ðŸ“¦ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(pages)} ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†")
    
    url_mapping = {}
    for url, _ in pages:
        parsed = urlparse(url)
        path = parsed.path.strip('/')
        local_path = "index.html" if not path else f"{path}/index.html"
        url_mapping[url] = local_path
        url_mapping[f"https://{domain}/{path}"] = local_path
        url_mapping[f"https://{domain}/{path}/"] = local_path
    
    print(f"ðŸ—ºï¸ ÐœÐ°Ð¿Ð¿Ð¸Ð½Ð³ ÑÐ¾Ð·Ð´Ð°Ð½ Ð´Ð»Ñ {len(url_mapping)} URL")
    
    processed = 0
    for url, html in pages:
        if not html:
            continue
        local_path = url_mapping.get(url)
        if not local_path:
            continue
        
        modified_html = rewrite_links(html, url, url_mapping, domain)
        output_file = output_dir / local_path
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text(modified_html, encoding='utf-8')
        
        processed += 1
        if processed % 50 == 0:
            print(f"âœ… {processed}/{len(pages)}...")
    
    conn.close()
    print(f"ðŸŽ‰ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ {processed} ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†")
    create_index(pages, output_dir, domain)

def rewrite_links(html, current_url, url_mapping, domain):
    parsed_current = urlparse(current_url)
    current_depth = len([p for p in parsed_current.path.strip('/').split('/') if p])
    
    # Ð­ÐºÑ€Ð°Ð½Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð² Ð´Ð¾Ð¼ÐµÐ½Ðµ Ð´Ð»Ñ regex
    domain_escaped = domain.replace('.', '\\.')
    
    patterns = [
        (rf'href="https?://{domain_escaped}(/[^"]*)"', 'href', '"'),
        (rf"href='https?://{domain_escaped}(/[^']*)'" , 'href', "'"),
        (rf'src="https?://{domain_escaped}(/[^"]*)"', 'src', '"'),
        (rf"src='https?://{domain_escaped}(/[^']*)'" , 'src', "'"),
    ]
    
    modified_html = html
    for pattern, attr, quote in patterns:
        def replacer(m):
            path = m.group(1).strip('/')
            if not path or path.startswith('#'):
                return m.group(0)
            
            target = f"https://{domain}/{path}"
            local = url_mapping.get(target) or url_mapping.get(f"{target}/")
            
            if local:
                prefix = '../' * current_depth if current_depth > 0 else ''
                return f'{attr}={quote}{prefix}{local}{quote}'
            return m.group(0)
        
        modified_html = re.sub(pattern, replacer, modified_html)
    
    return modified_html

def create_index(pages, output_dir, domain):
    html_start = f'''<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>{domain} Archive</title>
<style>
* {{ margin: 0; padding: 0; box-sizing: border-box; }}
body {{ font-family: system-ui; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 40px 20px; }}
.container {{ max-width: 1200px; margin: 0 auto; }}
h1 {{ color: white; text-align: center; margin-bottom: 40px; font-size: 2.5em; }}
.grid {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); gap: 20px; }}
.card {{ background: white; border-radius: 12px; padding: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); transition: transform 0.2s; }}
.card:hover {{ transform: translateY(-4px); }}
.url {{ font-size: 0.85em; color: #666; margin: 8px 0 12px; word-break: break-all; }}
.btn {{ display: inline-block; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 8px 16px; border-radius: 6px; text-decoration: none; }}
</style>
</head>
<body>
<div class="container">
<h1>ðŸ“– {domain} Archive ({{count}} pages)</h1>
<div class="grid">
'''
    
    cards = []
    for i, (url, _) in enumerate(pages, 1):
        path = urlparse(url).path.strip('/')
        local = f"{path}/index.html" if path else "index.html"
        cards.append(f'<div class="card"><h3>Page {i}</h3><div class="url">{url}</div><a href="{local}" class="btn">View â†’</a></div>')
    
    html_end = '''
</div>
</div>
</body>
</html>
'''
    
    final = html_start.replace('{count}', str(len(pages))) + '\n'.join(cards) + html_end
    (output_dir / "archive-index.html").write_text(final, encoding='utf-8')
    print("ðŸ“‹ Ð¡Ð¾Ð·Ð´Ð°Ð½ archive-index.html")

if __name__ == "__main__":
    process_archive()
EOFPYTHON
          
          python3 process_archive.py

      - name: Upload Pages Artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: pages

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
